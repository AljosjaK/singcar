% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BSDT_cov.R
\name{BSDT_cov}
\alias{BSDT_cov}
\title{Bayesian Standardised Difference Test with Covariates}
\usage{
BSDT_cov(
  case_tasks,
  case_covar,
  control_tasks,
  control_covar,
  alternative = c("two.sided", "greater", "less"),
  int.level = 0.95,
  calibrated = TRUE,
  iter = 1000,
  use_sumstats = FALSE,
  cor_mat = NULL,
  sample_size = NULL
)
}
\arguments{
\item{case_tasks}{A vector of length 2. The case scores from the two tasks.}

\item{case_covar}{A vector containing the case scores on all covariates
included.}

\item{control_tasks}{A matrix or dataframe with 2 columns and n rows
containing the control scores for the two tasks. Or a 2x2 matrix or dataframe
containing summary statistics where the first column represents the means
for each task and the second column represents the standard deviation.}

\item{control_covar}{A matrix or dataframe cointaining the control scores on
the covariates included. Or a matrix or dataframe containing summary
statistics where the first column represents the means for each covariate
and the second column represents the standard deviation.}

\item{alternative}{A character string specifying the alternative hypothesis,
must be one of \code{"two.sided"} (default), \code{"greater"} or
\code{"less"}. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as X and which is set
as Y, be very careful if changing this parameter.}

\item{int.level}{The probability level on the Bayesian credible intervals.}

\item{calibrated}{Whether or not to use the standard theory (Jeffreys) prior
distribution (if set to \code{FALSE}) or a calibrated prior examined by
Berger and Sun (2008) and sample size treated as n - 1. See Crawford et al.
(2011) for further information. Calibrated prior is recommended.}

\item{iter}{Number of iterations to be performed. Greater number gives better
estimation but takes longer to calculate.}

\item{use_sumstats}{If set to \code{TRUE}, \code{control_tasks} and
\code{control_covar} are treated as matrices with summary statistics. Where
the first column represents the means for each variable and the second
column represents the standard deviation.}

\item{cor_mat}{A correlation matrix of all variables included. NOTE: the two
first variables should be the tasks of interest.}

\item{sample_size}{An integer specifying the sample size of the controls.}
}
\value{
A list with class \code{"htest"} containing the following components:
  \tabular{llll}{ \code{statistic}   \tab the average z-value over
  \code{iter} number of iterations. \cr\cr \code{p.value}    \tab the average
  p-value over \code{iter} number of iterations. \cr\cr \code{estimate} \tab
  case scores expressed as z-scores on task X and Y. Standardised effect size
  (Z-DCCC) of task difference between case and controls and point estimate of
  the proportion of the control population estimated to show a more extreme
  task difference. \cr\cr  \code{null.value}   \tab the value of the
  difference between tasks under the null hypothesis.\cr\cr \code{interval}
  \tab named numerical vector containing level of confidence and confidence
  intervals for both effect size and p-value.\cr\cr \code{desc}     \tab data
  frame containing means and standard deviations for controls as well as case
  scores. \cr\cr \code{cor.mat} \tab matrix giving the correlations between
  the tasks of interest and the covariates included. \cr\cr
  \code{sample.size}     \tab number of controls. Remember, if
  \code{calibrated} left as default (i.e. \code{TRUE}) sample size is treated
  as n - 1.\cr\cr \code{alternative}     \tab a character string describing
  the alternative hypothesis.\cr\cr \code{method} \tab a character string
  indicating what type of test was performed.\cr\cr \code{data.name} \tab a
  character string giving the name(s) of the data}
}
\description{
Tests whether the standardized difference between a case's scores
on two tasks (A and B) is significantly different from the standardized
differences between these tasks in a control sample, while controlling for
the effects of covariates.  For example, it could be used to test whether a
case's standardized difference between two tasks is significantly greater
than the standardized differences in controls when controlling for a measure
of processing speed.  Under the null hypothesis the case's standardized
difference, conditioned on the covariate(s), is an observation from the
distribution of conditional standardized differences in the control
population. Returns (a) a signficance test, (b) point and
interval estimates of the effect size for the difference between the case and
controls, and (c) point and interval estimates of the abnormality of the
case's standardized difference (i.e., it estimates the percentage of controls
that would exhibit a more extreme standardized difference).
}
\details{
Developed by Crawford, Garthwaite and Ryan (2011).
}
\examples{
BSDT_cov(case_tasks = c(size_weight_illusion[1, "V_SWI"],
                        size_weight_illusion[1, "K_SWI"]),
         case_covar = size_weight_illusion[1, "YRS"],
         control_tasks = cbind(size_weight_illusion[-1, "V_SWI"],
                               size_weight_illusion[-1, "K_SWI"]),
         control_covar = size_weight_illusion[-1, "YRS"], iter = 100)

}
\references{
Berger, J. O., & Sun, D. (2008). Objective Priors for the Bivariate Normal
Model. \emph{The Annals of Statistics, 36}(2), 963-982. JSTOR.

Crawford, J. R., Garthwaite, P. H., & Ryan, K. (2011). Comparing a single
case to a control sample: Testing for neuropsychological deficits and
dissociations in the presence of covariates. \emph{Cortex, 47}(10),
1166-1178. https://doi.org/10.1016/j.cortex.2011.02.017
}
