% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BSDT.R
\name{BSDT}
\alias{BSDT}
\title{Bayesian Standardised Difference Test}
\usage{
BSDT(
  case.x,
  case.y,
  controls.x,
  controls.y,
  controls.x.sd = NULL,
  controls.y.sd = NULL,
  controls.n = NULL,
  cor.x.y = NULL,
  alternative = c("two.sided", "greater", "less"),
  int.level = 0.95,
  iter = 1000,
  unstandardised = FALSE,
  calibrated = FALSE,
  na.rm = FALSE
)
}
\arguments{
\item{case.x}{Case's score on task X.}

\item{case.y}{Case's score on task Y.}

\item{controls.x}{Controls' scores on task X. Takes either a vector of
observations or a single value interpreted as mean. \emph{Note}: you can
supply a vector as input for task X while mean and SD for task Y.}

\item{controls.y}{Controls' scores on task Y. Takes either a vector of
observations or a single value interpreted as mean. \emph{Note}: you can
supply a vector as input for task Y while mean and SD for task X.}

\item{controls.x.sd}{If single value for task X is given as input you must
supply the standard deviation of the sample.}

\item{controls.y.sd}{If single value for task Y is given as input you must
supply the standard deviation of the sample.}

\item{controls.n}{If X or Y is given as mean and SD you must supply the
sample size. If controls.x is given as vector and controls.y as mean and
SD, controls.n must equal the number of observations in controls.x.}

\item{cor.x.y}{If X or Y is given as mean and SD you must supply the
correlation between the tasks.}

\item{alternative}{A character string specifying the alternative hypothesis,
must be one of \code{"two.sided"} (default), \code{"greater"} or
\code{"less"}. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as X and which is set
as Y, be very careful if changing this parameter.}

\item{int.level}{Level of confidence for credible intervals.}

\item{iter}{Number of iterations. Greater number gives better
estimation but takes longer to calculate.}

\item{unstandardised}{Estimate z-value based on standardised or
unstandardised task scores.}

\item{calibrated}{set to \code{TRUE} to use a calibrated prior distribution.}

\item{na.rm}{Remove \code{NA}s from controls.}
}
\value{
A list with class \code{"htest"} containing the following components:
  \tabular{llll}{ \code{statistic}   \tab the average z-value over
  \code{iter} number of iterations. \cr\cr \code{p.value}    \tab the average
  p-value over \code{iter} number of iterations. \cr\cr \code{estimate} \tab
  case scores expressed as z-scores on task X and Y. Standardised effect size
  (Z-DCC) of task difference between case and controls and point estimate of
  the proportion of the control population estimated to show a more extreme
  task difference. \cr\cr  \code{null.value}   \tab the value of the
  difference under the null hypothesis.\cr\cr  \code{alternative}     \tab a
  character string describing the alternative hypothesis.\cr\cr \code{method}
  \tab a character string indicating what type of test was performed.\cr\cr
  \code{data.name} \tab a character string giving the name(s) of the data}
}
\description{
A test on the difference between two tasks in a single case, by comparison to
the difference of the same two tasks in a control sample. Calculates a
standardised effects size of task difference as well as a point estimate of
the proportion of the control population that would be expected to show a
more extreme task difference.
}
\examples{
BSDT(-3.857, -1.875, controls.x = 0, controls.y = 0, controls.x.sd = 1,
controls.y.sd = 1, controls.n = 20, cor.x.y = 0.68)
BSDT(-3.857, -1.875, controls.x = rnorm(20), controls.y = rnorm(20))

}
\references{
Crawford, J. R., & Garthwaite, P. H. (2007). Comparison of a single case to a
control or normative sample in neuropsychology: Development of a Bayesian
approach. \emph{Cognitive Neuropsychology, 24}(4), 343â€“372.
\url{https://doi.org/10.1080/02643290701290146}
}
